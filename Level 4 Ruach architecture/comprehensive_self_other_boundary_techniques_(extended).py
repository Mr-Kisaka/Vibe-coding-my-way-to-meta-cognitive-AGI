# -*- coding: utf-8 -*-
"""Comprehensive Self-Other Boundary Techniques (Extended)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t0VTegLdvu5S0xn4pA_uId5nlU7j_yvy

License: GNU Affero General Public License v3.0
"""

# consciousness_boundary_techniques.py

from abc import ABC, abstractmethod
import torch.nn as nn
import torch
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Any, Optional

# --- Abstract Base Classes for Modularity ---

class AbstractSelfRepresentationModel(ABC, nn.Module):
    """
    Abstract base class for neural architectures that aim to generate
    a representation of the 'self' and distinguish it from 'other' elements.
    Inherits from nn.Module for neural network capabilities.
    """
    @abstractmethod
    def get_self_representation(self, current_input: torch.Tensor, internal_state: Optional[Any] = None) -> torch.Tensor:
        """
        Extracts a numerical representation of the 'self' from current input and/or internal state.
        This representation should be distinct from 'other' elements.

        Args:
            current_input (torch.Tensor): The current input data (e.g., combined embeddings of internal processes or external interactions).
            internal_state (Optional[Any]): An optional previous internal state for recurrent models or complex architectures (can be a tuple for LSTM).

        Returns:
            torch.Tensor: A vector representing the 'self' or its distinction from 'other'.
        """
        pass

class AbstractBoundaryLearner(ABC):
    """
    Abstract base class for learning paradigms that explicitly learn to
    distinguish between 'self' and 'other' representations.
    """
    @abstractmethod
    def compute_loss(self, self_representations: List[torch.Tensor],
                     other_representations: List[torch.Tensor],
                     temporal_info: Optional[List[float]] = None,
                     episode_id: Optional[Any] = None) -> torch.Tensor:
        """
        Computes a loss that encourages separation between 'self' and 'other' representations.
        May also consider temporal consistency and episodic context.

        Args:
            self_representations (List[torch.Tensor]): A list of tensors representing instances of 'self'.
            other_representations (List[torch.Tensor]): A list of tensors representing instances of 'other'.
            temporal_info (Optional[List[float]]): Optional timestamps or sequential indices for temporal consistency.
            episode_id (Optional[Any]): An identifier for the current learning episode, for meta-learning or continual learning.

        Returns:
            torch.Tensor: A scalar loss value.
        """
        pass

class AbstractSelfMemory(ABC):
    """
    Abstract base class for memory architectures specifically designed to
    store, retrieve, and potentially manage 'self' memories over time.
    """
    @abstractmethod
    def store_self_state(self, self_representation: torch.Tensor, timestamp: float, metadata: Dict = None):
        """
        Stores a representation of the self along with its timestamp and optional metadata.

        Args:
            self_representation (torch.Tensor): A vector representing a state of the self.
            timestamp (float): The timestamp when this self-state occurred.
            metadata (Dict): Optional dictionary for additional information.
        """
        pass

    @abstractmethod
    def retrieve_self_state(self, query_representation: torch.Tensor, k: int, filter_criteria: Dict = None) -> List[Dict]:
        """
        Retrieves past 'self' states relevant to a query representation.

        Args:
            query_representation (torch.Tensor): The current self-representation used for querying.
            k (int): The number of top relevant self-states to retrieve.
            filter_criteria (Dict): Optional criteria to filter retrieved memories (e.g., by time range, type).

        Returns:
            List[Dict]: A list of dictionaries, each containing retrieved self-state, similarity, and metadata.
        """
        pass

class AbstractSelfWorldPredictor(ABC, nn.Module):
    """
    Abstract base class for cognitive frameworks that maintain self-world distinctions
    through prediction, inference, or sensorimotor grounding.
    Inherits from nn.Module for neural network capabilities.
    """
    @abstractmethod
    def predict_next_state(self, current_self_state: torch.Tensor, perceived_world_state: torch.Tensor, action: Optional[torch.Tensor] = None) -> Dict:
        """
        Predicts the next self and/or world states, highlighting discrepancies
        that can define self-world boundaries.

        Args:
            current_self_state (torch.Tensor): The current internal representation of the self.
            perceived_world_state (torch.Tensor): The current representation of the external world.
            action (Optional[torch.Tensor]): An optional action taken by the agent, influencing predictions.

        Returns:
            Dict: A dictionary containing predictions, prediction errors, and distinction signals.
        """
        pass


# --- Neural Architecture Approaches ---

class StandardAutoencoderSelf(AbstractSelfRepresentationModel):
    """
    Conceptual implementation of a standard autoencoder for self-representation.
    Learns to encode and decode internal states to form a compact 'self' vector.

    This contributes to temporal self-continuity by providing a consistent,
    compressed internal representation that can be tracked over time.
    The reconstruction error can serve as an implicit self-other boundary signal.
    """
    def __init__(self, input_dim: int, latent_dim: int = 256):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, latent_dim * 2),
            nn.ReLU(),
            nn.Linear(latent_dim * 2, latent_dim)
        )
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, latent_dim * 2),
            nn.ReLU(),
            nn.Linear(latent_dim * 2, input_dim)
        )
        # Placeholder for learned parameters, could be trained on VAE's mu, logvar or raw experience vectors
        self.learned_self_parameters = nn.Parameter(torch.randn(latent_dim))

    def get_self_representation(self, current_input: torch.Tensor, internal_state: Optional[Any] = None) -> torch.Tensor:
        """
        Processes current internal state (e.g., combined VAE latent, internal processes)
        through the autoencoder to derive a 'self' representation.

        Temporal Continuity: The output latent vector serves as a snapshot of self.
        Self-Other Boundary: High reconstruction error for external inputs vs internal.
        """
        # Ensure input_dim matches model's expected input
        if current_input.shape[-1] != self.encoder[0].in_features:
            # Pad or truncate for demonstration
            if current_input.shape[-1] > self.encoder[0].in_features:
                current_input = current_input[..., :self.encoder[0].in_features]
            else:
                padding = torch.zeros(*current_input.shape[:-1], self.encoder[0].in_features - current_input.shape[-1], device=current_input.device)
                current_input = torch.cat((current_input, padding), dim=-1)

        latent_self = self.encoder(current_input)
        # Example: Bias towards a learned 'canonical self'
        return latent_self + self.learned_self_parameters.unsqueeze(0)

class TransformerSelfAttention(AbstractSelfRepresentationModel):
    """
    Conceptual implementation of a Transformer encoder layer for self/other distinction.
    Self-attention mechanism explicitly compares input tokens (self-related vs. other-related).

    This contributes to temporal self-continuity by tracking relationships within sequences
    of self-tokens over time. The attention weights provide a direct mechanism for
    self/other distinction based on contextual relationships.
    """
    def __init__(self, d_model: int, nhead: int = 8, dim_feedforward: int = 2048):
        super().__init__()
        self.d_model = d_model
        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, batch_first=True)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)

    def get_self_representation(self, current_input: torch.Tensor, internal_state: Optional[Any] = None) -> torch.Tensor:
        """
        Processes 'self' and 'other' related tokens using self-attention.
        Assumes current_input contains concatenated self-tokens and other-tokens.

        Args:
            current_input (torch.Tensor): A batch of concatenated self_tokens and other_tokens,
                                         shape (batch_size, seq_len, d_model).
            internal_state (Optional[Any]): Not directly used in this stateless example,
                                                    but could be for sequence generation.

        Returns:
            torch.Tensor: Mean of the attended output corresponding to the self-tokens,
                          shape (batch_size, d_model).

        Temporal Continuity: Attention can track how self-tokens evolve and relate over time.
        Self-Other Boundary: Explicitly models relationships between self and other tokens,
                             with attention weights indicating distinction.
        """
        if current_input.shape[-1] != self.d_model:
            raise ValueError(f"Input d_model mismatch: expected {self.d_model}, got {current_input.shape[-1]}")

        # Assuming the first half of the sequence are 'self' tokens for simplicity
        # In a real scenario, explicit masking or token types would be used.
        num_self_tokens = current_input.shape[1] // 2

        attended_output = self.transformer_encoder(current_input)

        # For self/other distinction, focus on how 'self_tokens' attention to itself vs others
        # Return the mean representation of the 'self' portion of the output
        return attended_output[:, :num_self_tokens, :].mean(dim=1)

class RNNLSTMGURUSelfState(AbstractSelfRepresentationModel):
    """
    Conceptual implementation of an LSTM/GRU for self-state tracking.
    Maintains a hidden state that represents the continuous evolution of the 'self'.

    This contributes to temporal self-continuity by explicitly carrying forward
    an internal self-state. The update mechanisms (gates) allow for adaptive
    incorporation of new 'self' or 'other' information while maintaining coherence.
    """
    def __init__(self, input_dim: int, hidden_dim: int = 512, num_layers: int = 1, rnn_type: str = 'lstm'):
        super().__init__()
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        self.rnn_type = rnn_type.lower()

        if self.rnn_type == 'lstm':
            self.rnn = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)
        elif self.rnn_type == 'gru':
            self.rnn = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)
        else:
            self.rnn = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True)

        self.self_projection = nn.Linear(hidden_dim, input_dim) # Project hidden state back to input dim for consistency

    def get_self_representation(self, current_input: torch.Tensor, internal_state: Optional[Any] = None) -> torch.Tensor:
        """
        Processes current input (e.g., from parliament or interaction) and updates the
        recurrent hidden state to track the evolving self.

        Args:
            current_input (torch.Tensor): The current experience embedding, shape (batch_size, sequence_length, input_dim).
                                         If sequence_length is 1, wrap it in a list.
            internal_state (Optional[Any]): The previous hidden state(s) from the RNN/LSTM/GRU.
                                                     For LSTM: (h_n, c_n), For GRU/RNN: h_n.

        Returns:
            torch.Tensor: The new hidden state representing the updated 'self-state', shape (batch_size, hidden_dim).

        Temporal Continuity: Explicitly models the evolution of self through recurrent connections.
        Self-Other Boundary: Can learn to differentially gate internal vs. external influences on self-state.
        """
        if current_input.dim() == 2: # Add sequence_length dimension if missing
            current_input = current_input.unsqueeze(1)

        if self.rnn_type == 'lstm' and internal_state is not None:
            h_0, c_0 = internal_state
            # Ensure h_0, c_0 have correct shape (num_layers * num_directions, batch, hidden_size)
            h_0 = h_0.view(self.num_layers, current_input.size(0), self.hidden_dim)
            c_0 = c_0.view(self.num_layers, current_input.size(0), self.hidden_dim)
            output, (h_n, c_n) = self.rnn(current_input, (h_0, c_0))
            return h_n[-1] # Return the hidden state of the last layer
        elif internal_state is not None: # GRU or RNN
            h_0 = internal_state.view(self.num_layers, current_input.size(0), self.hidden_dim)
            output, h_n = self.rnn(current_input, h_0)
            return h_n[-1]
        else: # Initialize with zeros
            output, h_n = self.rnn(current_input)
            if self.rnn_type == 'lstm':
                return h_n[0][-1]
            return h_n[-1]

class GNNSelfOtherRelationship(AbstractSelfRepresentationModel):
    """
    Conceptual implementation of a Graph Neural Network for self-other relationship modeling.
    Represents entities (self, memories, external agents) as nodes and their interactions as edges.

    This contributes to temporal self-continuity by modeling the dynamic, relational aspects
    of the self. It learns a self-other boundary through the structure and strength of
    connections in the graph representing the self's interaction with its environment.
    """
    def __init__(self, node_feature_dim: int, edge_feature_dim: int, hidden_dim: int = 256):
        super().__init__()
        # In a full implementation, you'd use a library like PyTorch Geometric.
        # This is a highly simplified mock of a single graph convolution layer.
        self.node_feature_dim = node_feature_dim
        self.edge_feature_dim = edge_feature_dim
        self.hidden_dim = hidden_dim

        self.node_mlp = nn.Sequential(
            nn.Linear(node_feature_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim)
        )
        self.message_mlp = nn.Sequential(
            nn.Linear(2 * hidden_dim + edge_feature_dim, hidden_dim), # (Node_i + Node_j + Edge) -> Message
            nn.ReLU()
        )
        self.update_mlp = nn.Sequential(
            nn.Linear(hidden_dim + hidden_dim, hidden_dim), # (Node_i_current + Aggregated_Messages) -> New_Node_i
            nn.ReLU()
        )

        # A specific 'self_node' embedding
        self.self_node_embedding = nn.Parameter(torch.randn(1, hidden_dim))

    def get_self_representation(self, current_input: torch.Tensor, internal_state: Optional[Any] = None) -> torch.Tensor:
        """
        Takes a set of node features (representing various entities including 'self' and 'other')
        and adjacency/edge features, and processes them through a mock GNN layer.

        Args:
            current_input (torch.Tensor): Concatenated node features of all entities (including 'self' and 'other'),
                                         e.g., shape (batch_size, num_nodes, node_feature_dim).
                                         For this mock, we assume a single self node is part of these.
            internal_state (Optional[Any]): Optional additional graph structure (adjacency matrix, edge features).
                                                     For this mock, we assume `internal_state` is a tuple:
                                                     (adj_matrix: (batch, num_nodes, num_nodes), edge_features: (batch, num_edges, edge_feature_dim))

        Returns:
            torch.Tensor: The updated feature vector of the designated 'self' node,
                          shape (batch_size, hidden_dim).

        Temporal Continuity: Models how the self-node's relationships evolve over time.
        Self-Other Boundary: Differentiates self-node from other nodes through learned graph relationships.
        """
        if internal_state is None or not isinstance(internal_state, tuple) or len(internal_state) < 2:
            raise ValueError("GNNSelfOtherRelationship requires `internal_state` as (adj_matrix, edge_features).")

        node_features = current_input
        adj_matrix, edge_features = internal_state
        batch_size, num_nodes, _ = node_features.shape

        # Initial node embeddings
        h = self.node_mlp(node_features) # (batch, num_nodes, hidden_dim)

        # Simplified message passing (no actual edge feature use in message, for brevity)
        aggregated_messages = torch.zeros_like(h)
        # Mock message passing for simplicity: each node gets messages from all others
        for i in range(num_nodes):
            # Messages from neighbors to node i
            # In a real GNN, this would involve weighted aggregation based on adj_matrix
            messages_from_others = h.sum(dim=1) - h[:, i, :] # Sum of all other nodes' features
            aggregated_messages[:, i, :] = messages_from_others / (num_nodes - 1).clamp(min=1) # Average

        # Update nodes
        h_new = self.update_mlp(torch.cat((h, aggregated_messages), dim=-1))

        # Assuming the 'self' node is always the first node (index 0)
        # In a real setup, a specific node ID or mask would identify the self node.
        updated_self_node_representation = h_new[:, 0, :] + self.self_node_embedding # Combine with learned self bias

        return updated_self_node_representation

class SiameseSelfOtherComparison(AbstractSelfRepresentationModel):
    """
    Conceptual implementation of a Siamese network for direct self/other comparison.
    Comprises two identical subnetworks sharing weights to learn a similarity metric.

    This contributes to temporal self-continuity by continuously verifying
    the similarity of new internal states to past self-states. It establishes a
    self-other boundary by explicitly learning to push dissimilar (self vs. other)
    embeddings apart while pulling similar (self vs. self-generated) embeddings closer.
    """
    def __init__(self, embedding_dim: int, hidden_dim: int = 256):
        super().__init__()
        self.embedding_net = nn.Sequential(
            nn.Linear(embedding_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, embedding_dim) # Output same dimension as input
        )
        self.embedding_dim = embedding_dim

    def forward_one(self, x: torch.Tensor) -> torch.Tensor:
        """Passes one input through the shared embedding network."""
        return self.embedding_net(x)

    def get_self_representation(self, current_input: torch.Tensor, internal_state: Optional[Any] = None) -> torch.Tensor:
        """
        Processes a single input (e.g., an experience embedding) through the shared
        embedding network to get its representation. This is typically used internally
        by a `compute_loss` method for actual comparison, but here provides the embedding.

        Args:
            current_input (torch.Tensor): The input embedding (e.g., of an experience).
                                         Shape (batch_size, embedding_dim).
            internal_state (Optional[Any]): Not used here.

        Returns:
            torch.Tensor: The learned embedding of the input, shape (batch_size, embedding_dim).

        Temporal Continuity: Used to compare an evolving 'self' with previous 'self' states.
        Self-Other Boundary: The network is designed to output embeddings that are distinct
                             for self vs. other (when trained with contrastive loss).
        """
        if current_input.shape[-1] != self.embedding_dim:
            raise ValueError(f"Input embedding dimension mismatch: expected {self.embedding_dim}, got {current_input.shape[-1]}")
        return self.forward_one(current_input)

    def compute_similarity(self, embedding1: torch.Tensor, embedding2: torch.Tensor, metric: str = 'euclidean') -> torch.Tensor:
        """
        Computes a similarity score between two embeddings generated by the Siamese network.

        Args:
            embedding1 (torch.Tensor): First embedding.
            embedding2 (torch.Tensor): Second embedding.
            metric (str): 'euclidean' for Euclidean distance (lower is more similar), 'cosine' for cosine similarity (higher is more similar).

        Returns:
            torch.Tensor: A scalar or batch of similarity scores.
        """
        if metric == 'euclidean':
            return F.pairwise_distance(embedding1, embedding2)
        elif metric == 'cosine':
            return F.cosine_similarity(embedding1, embedding2)
        else:
            raise ValueError(f"Unsupported similarity metric: {metric}")

class CapsuleSelfRepresentation(AbstractSelfRepresentationModel):
    """
    Conceptual implementation of a Capsule Network for hierarchical self-representation.
    Uses vector-output capsules to represent different hierarchical aspects of the self.

    This contributes to temporal self-continuity by maintaining stable, pose-aware
    representations of self-components that can track transformations over time. It defines
    the self-other boundary by distinguishing how internal 'parts' of the self
    combine into a 'whole' versus how external entities are perceived.
    """
    def __init__(self, input_dim: int, num_primary_caps: int = 8, primary_cap_dim: int = 16,
                 num_digit_caps: int = 10, digit_cap_dim: int = 32):
        super().__init__()
        self.input_dim = input_dim
        self.num_primary_caps = num_primary_caps
        self.primary_cap_dim = primary_cap_dim
        self.num_digit_caps = num_digit_caps
        self.digit_cap_dim = digit_cap_dim

        # Simplified PrimaryCapsule Layer (e.g., from MLP instead of Conv for abstract embeddings)
        self.primary_capsules = nn.Linear(input_dim, num_primary_caps * primary_cap_dim)

        # Routing by agreement: weight for each primary capsule to each digit capsule
        self.W = nn.Parameter(torch.randn(num_primary_caps, num_digit_caps, primary_cap_dim, digit_cap_dim))

    def squash(self, s: torch.Tensor) -> torch.Tensor:
        """Squashing function for capsule outputs."""
        s_norm = s.norm(dim=-1, keepdim=True)
        return (s_norm**2 / (1 + s_norm**2)) * (s / (s_norm + 1e-8))

    def get_self_representation(self, current_input: torch.Tensor, internal_state: Optional[Any] = None) -> torch.Tensor:
        """
        Processes a high-dimensional input (e.g., from VAE or raw features) into
        hierarchical capsule representations that reflect the self's structure.

        Args:
            current_input (torch.Tensor): The input vector representing a state or experience.
                                         Shape (batch_size, input_dim).
            internal_state (Optional[Any]): Not used here.

        Returns:
            torch.Tensor: The combined output of the final layer of capsules, representing
                          a hierarchical 'self-state' representation.
                          Shape (batch_size, num_digit_caps * digit_cap_dim).

        Temporal Continuity: Vector properties and hierarchical nature preserve pose and relationships over time.
        Self-Other Boundary: Learns part-whole relationships within the self, distinguishing coherent self-structures
                             from fragmented external perceptions.
        """
        if current_input.shape[-1] != self.input_dim:
            raise ValueError(f"Input dimension mismatch: expected {self.input_dim}, got {current_input.shape[-1]}")

        batch_size = current_input.shape[0]

        # Primary Capsules
        # (batch_size, input_dim) -> (batch_size, num_primary_caps * primary_cap_dim)
        primary_output = self.primary_capsules(current_input).view(batch_size, self.num_primary_caps, self.primary_cap_dim)
        primary_output = self.squash(primary_output) # (batch_size, num_primary_caps, primary_cap_dim)

        # Dynamic Routing (simplified for skeleton)
        # This would typically involve iterations of routing
        # Primary caps (batch, p_num, p_dim) x W (p_num, d_num, p_dim, d_dim)
        # -> (batch, p_num, d_num, d_dim) - prediction vectors
        # For simplicity, let's just do a direct transformation and sum
        predictions = torch.einsum('bpd,pdcd->bpcd', primary_output, self.W)

        # Sum predictions to get final capsule output (after routing, which is skipped here)
        digit_caps_output = self.squash(predictions.sum(dim=1)) # (batch, num_digit_caps, digit_cap_dim)

        # Flatten for a single self-representation vector
        return digit_caps_output.view(batch_size, -1)

class ReservoirComputingSelf(AbstractSelfRepresentationModel):
    """
    Conceptual implementation of Reservoir Computing (Echo State Network) for temporal self-tracking.
    Leverages a randomly connected recurrent neural network (reservoir) with a simple linear readout layer.

    This contributes to temporal self-continuity by implicitly capturing complex temporal dynamics
    of the self-state within its recurrent reservoir, without explicit training of the recurrent weights.
    The self-other boundary can be inferred from the distinct dynamic patterns generated by internal
    (self) vs. external (other) inputs within the reservoir.
    """
    def __init__(self, input_dim: int, reservoir_dim: int = 500, spectral_radius: float = 0.9, density: float = 0.1):
        super().__init__()
        self.input_dim = input_dim
        self.reservoir_dim = reservoir_dim
        self.spectral_radius = spectral_radius

        # Input weights (random, fixed)
        self.W_in = nn.Parameter(torch.randn(reservoir_dim, input_dim), requires_grad=False)

        # Reservoir weights (random, fixed, scaled by spectral radius)
        W_res = torch.randn(reservoir_dim, reservoir_dim)
        W_res = W_res * (spectral_radius / torch.max(torch.abs(torch.linalg.eigvals(W_res))))
        self.W_res = nn.Parameter(W_res, requires_grad=False)

        # Readout layer (trained linearly)
        self.readout = nn.Linear(reservoir_dim, input_dim) # Readout to predict next input or self-representation

        # Internal state of the reservoir
        self.register_buffer('reservoir_state', torch.zeros(1, reservoir_dim))

    def _update_reservoir(self, current_input: torch.Tensor):
        """Updates the reservoir state with a new input."""
        # current_input: (batch_size, input_dim)
        if current_input.dim() == 1:
            current_input = current_input.unsqueeze(0) # Add batch dimension

        prev_state = self.reservoir_state

        # Ensure prev_state matches batch size of current_input
        if prev_state.shape[0] != current_input.shape[0]:
            prev_state = prev_state.expand(current_input.shape[0], -1)

        # Reservoir dynamics
        new_state = torch.tanh(
            torch.matmul(current_input, self.W_in.T) +
            torch.matmul(prev_state, self.W_res.T)
        )
        self.reservoir_state = new_state.detach() # Detach to prevent gradients from flowing into fixed weights

    def get_self_representation(self, current_input: torch.Tensor, internal_state: Optional[Any] = None) -> torch.Tensor:
        """
        Updates the reservoir with the current input and returns the current reservoir state
        as the 'self' representation.

        Args:
            current_input (torch.Tensor): The current experience embedding.
                                         Shape (batch_size, input_dim).
            internal_state (Optional[Any]): Not used directly here, as reservoir_state is internal.

        Returns:
            torch.Tensor: The current internal state of the reservoir, serving as the
                          temporal self-representation. Shape (batch_size, reservoir_dim).

        Temporal Continuity: Reservoir's recurrent dynamics intrinsically track self-evolution.
        Self-Other Boundary: Distinct reservoir dynamics for self-generated vs. external inputs.
        """
        if current_input.shape[-1] != self.input_dim:
            raise ValueError(f"Input dimension mismatch: expected {self.input_dim}, got {current_input.shape[-1]}")

        self._update_reservoir(current_input)
        return self.reservoir_state # The reservoir state itself is the self-representation

class HierarchicalMultiscaleSelf(AbstractSelfRepresentationModel):
    """
    Conceptual implementation for maintaining self-representation at multiple temporal scales simultaneously.
    Uses multiple recurrent layers, each operating at a different temporal granularity (e.g., fast, medium, slow).

    This contributes to temporal self-continuity by providing a robust, multi-faceted view of the self
    that is stable across long periods (slow scale) while being responsive to immediate events (fast scale).
    The self-other boundary is maintained by differentiating which scales are predominantly influenced
    by internal vs. external dynamics.
    """
    def __init__(self, input_dim: int, hidden_dim: int = 256, num_scales: int = 3):
        super().__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.num_scales = num_scales

        # Each scale has its own GRU
        self.scale_grus = nn.ModuleList([
            nn.GRU(input_dim if i == 0 else hidden_dim, hidden_dim, batch_first=True) for i in range(num_scales)
        ])

        # Learnable downsampling/upsampling or gating for inter-scale communication
        self.scale_integrators = nn.ModuleList([
            nn.Linear(hidden_dim * 2, hidden_dim) if i > 0 else None for i in range(num_scales) # Input from previous scale + current scale
        ])

        # Store hidden states for each scale
        self.register_buffer('hidden_states_per_scale', torch.zeros(num_scales, 1, hidden_dim)) # (num_scales, batch, hidden_dim)

    def get_self_representation(self, current_input: torch.Tensor, internal_state: Optional[Any] = None) -> torch.Tensor:
        """
        Processes current input through multiple GRUs operating at different temporal scales.
        Returns a concatenated representation of all scale states.

        Args:
            current_input (torch.Tensor): The current experience embedding.
                                         Shape (batch_size, input_dim).
            internal_state (Optional[Any]): Optional, can be used to pass previous hidden states.

        Returns:
            torch.Tensor: A concatenated tensor of the hidden states from all scales,
                          representing the multi-scale self-representation.
                          Shape (batch_size, hidden_dim * num_scales).

        Temporal Continuity: Explicitly models self-evolution at various speeds, ensuring stability and responsiveness.
        Self-Other Boundary: By observing dynamics at each scale, the system can discern if a change is a rapid external event
                             or a slow, internal evolution of self.
        """
        if current_input.dim() == 1:
            current_input = current_input.unsqueeze(0) # Add batch dimension
        if current_input.shape[-1] != self.input_dim:
            raise ValueError(f"Input dimension mismatch: expected {self.input_dim}, got {current_input.shape[-1]}")

        batch_size = current_input.shape[0]
        all_scale_outputs = []

        # Process through each scale
        for i, gru_layer in enumerate(self.scale_grus):
            current_h_state = self.hidden_states_per_scale[i].expand(batch_size, -1) # Expand to current batch size

            if i == 0: # Fast scale, takes raw input
                output, h_n = gru_layer(current_input.unsqueeze(1), current_h_state.unsqueeze(0))
            else: # Slower scales, take input from previous scale's output or integrated signal
                # For simplicity, let's pass a downsampled/integrated version of the previous scale's output
                # Or a simple pass-through of current_input, allowing GRU's recurrence to define scale
                # Here we use a conceptual 'integrated_input' from the previous scale's output.
                # For a skeleton, let's simply feed the current_input through all scales.
                # A more advanced model would use pooling/gating for actual multi-scale processing.
                output, h_n = gru_layer(current_input.unsqueeze(1), current_h_state.unsqueeze(0))

            self.hidden_states_per_scale[i] = h_n.detach().squeeze(0) # Update internal state, detach
            all_scale_outputs.append(h_n.squeeze(0))

        return torch.cat(all_scale_outputs, dim=-1)

class NeurosymbolicSelfRepresentation(AbstractSelfRepresentationModel):
    """
    Conceptual implementation of Neurosymbolic Integration for self-representation.
    Combines continuous neural embeddings with discrete symbolic rules/facts for self-knowledge.

    This contributes to temporal self-continuity by providing a robust, explicit, and interpretable
    symbolic knowledge base of the self alongside its fluid neural representation.
    The self-other boundary is established both by the neural distinction of experiences and
    by symbolic rules that define 'what I am' and 'what I am not'.
    """
    def __init__(self, neural_embedding_dim: int, symbolic_fact_dim: int = 100):
        super().__init__()
        self.neural_embedding_dim = neural_embedding_dim
        self.symbolic_fact_dim = symbolic_fact_dim

        # Neural component for continuous self-representation
        self.neural_encoder = nn.Sequential(
            nn.Linear(neural_embedding_dim, neural_embedding_dim),
            nn.ReLU()
        )
        # Symbolic component: a lookup table or a small network to process symbolic facts
        # For a skeleton, we use an embedding layer for symbolic facts.
        self.symbolic_embeddings = nn.Embedding(num_embeddings=10, embedding_dim=symbolic_fact_dim) # 10 conceptual facts

        # Fusion layer
        self.fusion_mlp = nn.Sequential(
            nn.Linear(neural_embedding_dim + symbolic_fact_dim, neural_embedding_dim),
            nn.ReLU()
        )

        # Placeholder for symbolic knowledge base (e.g., list of facts, rules)
        self.symbolic_kb = ["I am an AI", "I learn from experience", "I respond to users", "I have goals"]
        self.symbolic_fact_map = {fact: i for i, fact in enumerate(self.symbolic_kb)}


    def get_self_representation(self, current_input: torch.Tensor, internal_state: Optional[Any] = None) -> torch.Tensor:
        """
        Combines a continuous neural embedding (e.g., from VAE) with symbolic facts
        about the self to form a fused self-representation.

        Args:
            current_input (torch.Tensor): The current neural embedding of an experience or self-state.
                                         Shape (batch_size, neural_embedding_dim).
            internal_state (Optional[Any]): Optional symbolic facts (e.g., indices of active facts).

        Returns:
            torch.Tensor: A fused neurosymbolic representation of the self.
                          Shape (batch_size, neural_embedding_dim).

        Temporal Continuity: Explicit symbolic facts provide stable identity anchors; neural part tracks fluid changes.
        Self-Other Boundary: Neural part differentiates fluid experiences; symbolic rules explicitly define self vs. non-self.
        """
        if current_input.shape[-1] != self.neural_embedding_dim:
            raise ValueError(f"Neural input dimension mismatch: expected {self.neural_embedding_dim}, got {current_input.shape[-1]}")

        # Process neural input
        neural_rep = self.neural_encoder(current_input)

        # Process symbolic facts (for skeleton, use a fixed set of active facts)
        if internal_state is None:
            # Use a conceptual 'current symbolic self-state' for the batch
            # E.g., assume 2 symbolic facts are always active for simplicity
            active_fact_indices = torch.tensor([self.symbolic_fact_map["I am an AI"], self.symbolic_fact_map["I learn from experience"]], device=current_input.device).unsqueeze(0).expand(current_input.shape[0], -1)
            symbolic_rep = self.symbolic_embeddings(active_fact_indices).mean(dim=1) # (batch_size, symbolic_fact_dim)
        else:
            # If internal_state provides specific fact indices
            symbolic_rep = self.symbolic_embeddings(internal_state).mean(dim=1)

        # Fuse
        fused_rep = self.fusion_mlp(torch.cat([neural_rep, symbolic_rep], dim=-1))
        return fused_rep


# --- Learning Paradigms ---

class ContrastiveSelfOther(AbstractBoundaryLearner):
    """
    Conceptual implementation of a contrastive learning objective for self/other distinction.
    Maximizes similarity for 'self' pairs, minimizes for 'self' vs. 'other' pairs.

    This explicitly learns a self-other boundary by optimizing the embedding space
    to separate distinct categories. Temporal continuity can be enforced by
    designing positive pairs from sequential self-states.
    """
    def __init__(self, temperature: float = 0.5):
        self.temperature = temperature

    def compute_loss(self, self_representations: List[torch.Tensor],
                     other_representations: List[torch.Tensor],
                     temporal_info: Optional[List[float]] = None,
                     episode_id: Optional[Any] = None) -> torch.Tensor:
        """
        Computes a simplified InfoNCE-like loss for self vs. other.
        Assumes each list contains batch-first tensors.

        Args:
            self_representations (List[torch.Tensor]): List of self-embeddings.
            other_representations (List[torch.Tensor]): List of other-embeddings.
            temporal_info (Optional[List[float]]): Not directly used in this simplified loss,
                                                   but would inform positive pair selection.
            episode_id (Optional[Any]): Not used here.

        Returns:
            torch.Tensor: A scalar contrastive loss value.

        Temporal Continuity: Can be enforced by selecting temporally close self-states as positive pairs.
        Self-Other Boundary: Directly learns to separate self-embeddings from other-embeddings.
        """
        if not self_representations or not other_representations:
            return torch.tensor(0.0, requires_grad=True)

        # For simplicity, take the first from each list as anchor
        anchor_self = self_representations[0]
        anchor_other = other_representations[0]

        # Combine all self and other representations for negative samples
        all_reps = torch.cat(self_representations + other_representations, dim=0)

        # Simplified loss: Maximize similarity of anchor_self to other self_reps,
        # minimize similarity of anchor_self to other_reps.
        # This is a very basic form and not a full InfoNCE.

        # Positive similarity (anchor_self to all other self_reps)
        pos_sim = F.cosine_similarity(anchor_self.unsqueeze(1), torch.cat(self_representations[1:]).unsqueeze(0), dim=-1).mean() if len(self_representations) > 1 else torch.tensor(1.0)

        # Negative similarity (anchor_self to all other_reps)
        neg_sim = F.cosine_similarity(anchor_self.unsqueeze(1), torch.cat(other_representations).unsqueeze(0), dim=-1).mean()

        # A conceptual contrastive loss:
        # We want pos_sim to be high and neg_sim to be low.
        # A simple margin-based loss: max(0, margin - (pos_sim - neg_sim))
        # Or a log-softmax-like loss (InfoNCE) for more robustness
        loss = -torch.log(torch.exp(pos_sim / self.temperature) / (torch.exp(pos_sim / self.temperature) + torch.exp(neg_sim / self.temperature)))

        return loss

class MetaLearningSelfEpisode(AbstractBoundaryLearner):
    """
    Conceptual meta-learning approach where the model learns to learn about itself
    across episodes, enabling adaptive self-other distinction.

    This contributes to temporal self-continuity by learning an adaptive strategy
    for maintaining self-identity across changing contexts or 'episodes'. It enables
    a flexible self-other boundary that can quickly re-establish itself.
    """
    def __init__(self, meta_learner_model: nn.Module):
        self.meta_learner_model = meta_learner_model # E.g., a small MLP that outputs new learning rates or initializations

    def compute_loss(self, self_representations: List[torch.Tensor],
                     other_representations: List[torch.Tensor],
                     temporal_info: Optional[List[float]] = None,
                     episode_id: Optional[Any] = None) -> torch.Tensor:
        """
        Computes a meta-loss. In a true meta-learning setup, this would involve
        training the `meta_learner_model` on a set of 'self-other' tasks
        (support set) and evaluating on a 'query set'.

        Args:
            self_representations (List[torch.Tensor]): Self-embeddings from a meta-task episode.
            other_representations (List[torch.Tensor]): Other-embeddings from a meta-task episode.
            temporal_info (Optional[List[float]]): Temporal context of the episode.
            episode_id (Optional[Any]): Identifier for the current episode.

        Returns:
            torch.Tensor: A scalar meta-loss that quantifies how well the
                          meta-learner enabled rapid self-other distinction in the episode.

        Temporal Continuity: Learns an adaptive strategy for maintaining identity across episodes.
        Self-Other Boundary: Learns to quickly distinguish self from other in new contexts.
        """
        if not self_representations or not other_representations:
            return torch.tensor(0.0, requires_grad=True)

        # Mock meta-loss: encourage faster convergence of a dummy inner loop
        # This is a very abstract representation.
        dummy_inner_model = nn.Linear(self_representations[0].shape[-1], 1)
        optimizer = torch.optim.SGD(dummy_inner_model.parameters(), lr=0.1)

        # Simulate a few inner-loop updates on a task
        for _ in range(3): # 3 inner loop steps
            # A simple classification-like loss for self vs other in this episode
            self_scores = dummy_inner_model(torch.cat(self_representations))
            other_scores = dummy_inner_model(torch.cat(other_representations))

            # Simple binary classification loss where self is 1, other is 0
            inner_loss = F.binary_cross_entropy_with_logits(self_scores, torch.ones_like(self_scores)) + \
                         F.binary_cross_entropy_with_logits(other_scores, torch.zeros_like(other_scores))

            optimizer.zero_grad()
            inner_loss.backward(retain_graph=True)
            optimizer.step()

        # The meta-loss is how well the inner model performs after these few steps
        # This is a highly simplified proxy for demonstration
        meta_loss = inner_loss # E.g., final loss on query set

        return meta_loss

class RLAgentIdentityValue(AbstractBoundaryLearner):
    """
    Conceptual Reinforcement Learning paradigm where agent identity is maintained
    via a value function, providing rewards for self-consistent states.

    This contributes to temporal self-continuity by actively valuing and
    reinforcing actions and internal states that maintain identity. It learns
    a self-other boundary through the reward landscape that implicitly
    favors self-preserving and self-coherent states.
    """
    def __init__(self, state_dim: int, action_dim: int, reward_fn_model: nn.Module):
        self.state_dim = state_dim
        self.action_dim = action_dim
        self.reward_fn_model = reward_fn_model # A small neural net that predicts reward

        # A simple Q-network or value network for a conceptual agent
        self.q_network = nn.Sequential(
            nn.Linear(state_dim, 256),
            nn.ReLU(),
            nn.Linear(256, action_dim) # Outputs Q-values for actions
        )

    def compute_loss(self, self_representations: List[torch.Tensor],
                     other_representations: List[torch.Tensor],
                     temporal_info: Optional[List[float]] = None,
                     episode_id: Optional[Any] = None) -> torch.Tensor:
        """
        Computes an RL-inspired loss that rewards maintenance of self-identity.
        This would typically be a TD-error or policy gradient loss.

        Args:
            self_representations (List[torch.Tensor]): Recent sequence of self-states.
            other_representations (List[torch.Tensor]): Recent sequence of other-states/perceptions.
            temporal_info (Optional[List[float]]): Temporal sequence of (state, action, reward, next_state).
            episode_id (Optional[Any]): Not used here.

        Returns:
            torch.Tensor: A scalar RL loss (e.g., TD error or policy gradient) that
                          encourages actions maintaining self-identity.

        Temporal Continuity: Agent actively optimizes for long-term rewards tied to self-consistency.
        Self-Other Boundary: Reward function values self-coherent states and penalizes identity diffusion.
        """
        if not self_representations or not other_representations or not temporal_info:
            return torch.tensor(0.0, requires_grad=True)

        # For conceptual RL: Assume temporal_info provides a mock (state, action, reward, next_state, done) tuple
        # This would be a batch of experience tuples for training.
        mock_state = self_representations[0] # Current 'self' state
        mock_action_taken = torch.randint(0, self.action_dim, (1,))

        # Reward is higher if current_self is "distinct" from recent other_reps
        # and "consistent" with recent self_reps
        current_self_rep = self_representations[-1] if self_representations else torch.zeros(self.state_dim)

        if len(self_representations) > 1:
            consistency_reward = F.cosine_similarity(current_self_rep, self_representations[-2], dim=-1).mean()
        else:
            consistency_reward = torch.tensor(0.0)

        if other_representations:
            distinction_penalty = -F.cosine_similarity(current_self_rep, other_representations[-1], dim=-1).mean()
        else:
            distinction_penalty = torch.tensor(0.0)

        # Mock reward from the internal reward model
        mock_reward = self.reward_fn_model(torch.cat((current_self_rep, consistency_reward.unsqueeze(0), distinction_penalty.unsqueeze(0))))

        # Mock next state and Q-values
        mock_next_state = self_representations[0] + torch.randn_like(self_representations[0]) * 0.1
        max_next_q = self.q_network(mock_next_state).max(dim=-1).values

        # Simplified TD-error loss (Q-learning like)
        target_q = mock_reward + 0.99 * max_next_q
        current_q = self.q_network(mock_state).gather(1, mock_action_taken.unsqueeze(1)).squeeze(1)

        loss = F.mse_loss(current_q, target_q.detach()) # Detach target_q to stabilize
        return loss

class GANSelfExternalDiscriminator(AbstractBoundaryLearner, nn.Module):
    """
    Conceptual Generative Adversarial Network (GAN) setup where a discriminator
    distinguishes between 'self-generated' and 'external' content.

    This explicitly learns a self-other boundary by training a discriminator
    to identify the source of an experience. Temporal continuity is implicitly
    reinforced as the generator strives to produce increasingly self-consistent
    outputs to fool the discriminator.
    """
    def __init__(self, embedding_dim: int, hidden_dim: int = 256):
        super().__init__()
        # Discriminator: takes an embedding and classifies as 'self' or 'external'
        self.discriminator = nn.Sequential(
            nn.Linear(embedding_dim, hidden_dim),
            nn.LeakyReLU(0.2),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.LeakyReLU(0.2),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid() # Output probability of being 'self-generated'
        )
        # Generator (conceptual, not implemented here directly) would produce 'self' content

    def compute_loss(self, self_representations: List[torch.Tensor],
                     other_representations: List[torch.Tensor],
                     temporal_info: Optional[List[float]] = None,
                     episode_id: Optional[Any] = None) -> torch.Tensor:
        """
        Computes the discriminator loss for distinguishing self-generated from external content.
        (A full GAN would also have a generator loss).

        Args:
            self_representations (List[torch.Tensor]): Embeddings considered 'self-generated'.
            other_representations (List[torch.Tensor]): Embeddings considered 'external'/'real'.
            temporal_info (Optional[List[float]]): Not used here.
            episode_id (Optional[Any]): Not used here.

        Returns:
            torch.Tensor: A scalar discriminator loss value.

        Temporal Continuity: Generator learns to produce temporally consistent self-content.
        Self-Other Boundary: Discriminator directly learns to distinguish self-generated from external.
        """
        if not self_representations or not other_representations:
            return torch.tensor(0.0, requires_grad=True)

        real_data = torch.cat(other_representations) # External content is 'real'
        fake_data = torch.cat(self_representations) # Self-generated content is 'fake'

        # Labels: 1 for real (external), 0 for fake (self-generated)
        real_labels = torch.ones(real_data.shape[0], 1, device=real_data.device)
        fake_labels = torch.zeros(fake_data.shape[0], 1, device=fake_data.device)

        # Discriminator's performance on real and fake samples
        real_output = self.discriminator(real_data)
        fake_output = self.discriminator(fake_data)

        # Binary Cross-Entropy Loss for discriminator
        discriminator_real_loss = F.binary_cross_entropy(real_output, real_labels)
        discriminator_fake_loss = F.binary_cross_entropy(fake_output, fake_labels)

        total_discriminator_loss = discriminator_real_loss + discriminator_fake_loss
        return total_discriminator_loss

class SelfSupervisedTemporalConsistency(AbstractBoundaryLearner):
    """
    Conceptual self-supervised learning objective for temporal self-consistency.
    Learns robust representations by predicting or reconstructing temporally related self-states.

    This contributes to temporal self-continuity by explicitly training the model
    to predict or reconstruct its own internal states over time. It makes deviations
    from self-consistency salient, implicitly aiding the self-other boundary.
    """
    def __init__(self, prediction_model: nn.Module):
        self.prediction_model = prediction_model # E.g., a Transformer or MLP to predict future self-state

    def compute_loss(self, self_representations: List[torch.Tensor],
                     other_representations: List[torch.Tensor],
                     temporal_info: Optional[List[float]] = None,
                     episode_id: Optional[Any] = None) -> torch.Tensor:
        """
        Computes a self-supervised loss for temporal consistency of self-representations.
        (e.g., predicting next self-state, or reconstructing a masked self-state).

        Args:
            self_representations (List[torch.Tensor]): A sequence of self-embeddings.
            other_representations (List[torch.Tensor]): Not directly used here, but could
                                                         provide context for self-prediction.
            temporal_info (Optional[List[float]]): Timestamps or sequence indices, crucial for this task.
            episode_id (Optional[Any]): Not used here.

        Returns:
            torch.Tensor: A scalar self-supervised loss value.

        Temporal Continuity: Directly optimizes for coherent and predictable self-evolution.
        Self-Other Boundary: Makes inconsistencies with the self-trajectory salient, implicitly aiding distinction.
        """
        if len(self_representations) < 2 or not temporal_info:
            return torch.tensor(0.0, requires_grad=True)

        # Example: Predict the next self-representation given the current one
        current_self = self_representations[:-1]
        next_self = self_representations[1:]

        if not current_self or not next_self: # Safety check for very short lists
            return torch.tensor(0.0, requires_grad=True)

        # Concatenate into batches for prediction
        current_self_batch = torch.cat(current_self, dim=0)
        next_self_batch = torch.cat(next_self, dim=0)

        predicted_next_self = self.prediction_model(current_self_batch)

        loss = F.mse_loss(predicted_next_self, next_self_batch) # Reconstruction/prediction loss
        return loss

class ContinualLearningSelfIdentity(AbstractBoundaryLearner):
    """
    Conceptual Continual Learning approach for maintaining self-identity while learning new information.
    Aims to prevent catastrophic forgetting of previously learned self-definitions or distinctions.

    This contributes to temporal self-continuity by ensuring that the foundational,
    long-term representation of the self remains stable and accessible even as the system
    acquires new experiences and knowledge. It reinforces the self-other boundary by
    preserving the learned distinction mechanisms against new data.
    """
    def __init__(self, base_model: nn.Module, regularizer_strength: float = 1.0):
        self.base_model = base_model # The core model whose parameters need protection (e.g., VAE encoder)
        self.regularizer_strength = regularizer_strength
        self.old_params = {name: param.clone().detach() for name, param in base_model.named_parameters()}

        # Placeholder for importance weights (e.g., Fisher Information Matrix diagonals)
        self.param_importance = {name: torch.ones_like(param).detach() for name, param in base_model.named_parameters()}

    def update_old_parameters(self):
        """Saves current parameters as 'old' for regularization against catastrophic forgetting."""
        self.old_params = {name: param.clone().detach() for name, param in self.base_model.named_parameters()}
        # In a full EWC/SI implementation, param_importance would be updated here based on new task

    def compute_loss(self, self_representations: List[torch.Tensor],
                     other_representations: List[torch.Tensor],
                     temporal_info: Optional[List[float]] = None,
                     episode_id: Optional[Any] = None) -> torch.Tensor:
        """
        Computes a loss that includes a regularization term to prevent forgetting
        the previously learned self-identity. (e.g., EWC or Synaptic Intelligence inspired).

        Args:
            self_representations (List[torch.Tensor]): Current self-embeddings.
            other_representations (List[torch.Tensor]): Current other-embeddings.
            temporal_info (Optional[List[float]]): Not used here.
            episode_id (Optional[Any]): Current learning episode/task ID.

        Returns:
            torch.Tensor: A scalar loss value with a regularization term.

        Temporal Continuity: Prevents catastrophic forgetting of core self-knowledge.
        Self-Other Boundary: Preserves learned distinction mechanisms when new info arrives.
        """
        # Conceptual task loss (e.g., a simple self-other classification loss)
        if not self_representations or not other_representations:
            task_loss = torch.tensor(0.0, requires_grad=True)
        else:
            # Mock a task loss for current data (e.g., from a dummy classifier on base_model output)
            dummy_classifier = nn.Linear(self_representations[0].shape[-1], 2).to(self_representations[0].device)
            self_logits = dummy_classifier(torch.cat(self_representations))
            other_logits = dummy_classifier(torch.cat(other_representations))
            task_loss = F.cross_entropy(self_logits, torch.zeros(self_logits.shape[0], dtype=torch.long, device=self_logits.device)) + \
                        F.cross_entropy(other_logits, torch.ones(other_logits.shape[0], dtype=torch.long, device=other_logits.device))

        # Regularization term (Elastic Weight Consolidation / Synaptic Intelligence inspired)
        regularization_loss = torch.tensor(0.0, device=task_loss.device)
        for name, param in self.base_model.named_parameters():
            if name in self.old_params and name in self.param_importance:
                # Penalize changes to important parameters from previous tasks
                regularization_loss += (self.param_importance[name] * (param - self.old_params[name])**2).sum()

        return task_loss + self.regularizer_strength * regularization_loss


# --- Memory Architectures ---

class HopfieldAssociativeSelfMemory(AbstractSelfMemory):
    """
    Conceptual implementation of a Hopfield network for associative self-memory.
    Stores and retrieves complete 'self' patterns from partial or noisy cues.

    This contributes to temporal self-continuity by providing a robust mechanism
    for recalling consistent self-states, ensuring that the system can always
    converge to a coherent self-identity. It strengthens the self-other boundary
    by completing inputs to stored 'self' patterns, rejecting 'other' patterns.
    """
    def __init__(self, pattern_dim: int, num_patterns: int = 100):
        self.pattern_dim = pattern_dim
        self.num_patterns = num_patterns
        self.stored_patterns = [] # List of (timestamp, pattern_tensor)

        # Placeholder for the weight matrix in a true Hopfield Net
        self.weights = torch.zeros(pattern_dim, pattern_dim)

    def store_self_state(self, self_representation: torch.Tensor, timestamp: float, metadata: Dict = None):
        """
        Stores a binarized self-representation as a pattern in the associative memory.
        (Hopfield networks typically work with binary patterns).
        """
        # For simplicity, binarize the input (e.g., sign of values)
        binarized_pattern = (self_representation > 0).float() * 2 - 1 # Convert to {-1, 1}
        self.stored_patterns.append({'timestamp': timestamp, 'pattern': binarized_pattern.squeeze(0), 'metadata': metadata or {}})

        # In a true Hopfield net, weights would be updated (Hebbian learning)
        # self.weights += torch.outer(binarized_pattern, binarized_pattern) # Simplified

        # Keep memory bounded
        if len(self.stored_patterns) > self.num_patterns:
            self.stored_patterns.pop(0)


    def retrieve_self_state(self, query_representation: torch.Tensor, k: int = 1, filter_criteria: Dict = None) -> List[Dict]:
        """
        Retrieves the self-state most similar to the query by 'converging' to a stored pattern.
        """
        if not self.stored_patterns:
            return []

        # Binarize query
        query_binarized = (query_representation > 0).float() * 2 - 1

        # Simulate convergence to the closest stored pattern
        # This is a very simplified (non-iterative) mock.
        similarities = []
        for i, entry in enumerate(self.stored_patterns):
            stored_pattern = entry['pattern']
            # Calculate overlap (dot product)
            similarity = torch.dot(query_binarized.squeeze(0), stored_pattern)
            similarities.append((similarity.item(), entry))

        similarities.sort(key=lambda x: x[0], reverse=True)

        retrieved = []
        for sim, entry in similarities[:k]:
            retrieved.append({
                'similarity': sim,
                'self_state': entry['pattern'],
                'timestamp': entry['timestamp'],
                'metadata': entry['metadata']
            })
        return retrieved

class AttentionBasedSelfOtherMemory(AbstractSelfMemory, nn.Module):
    """
    Conceptual implementation of an Attention-Based Memory with explicit self/other addressing.
    Uses attention mechanisms to selectively retrieve self-relevant memories from a memory bank.

    This contributes to temporal self-continuity by enabling the system to retrieve
    past self-states highly relevant to its current internal context. It explicitly learns
    the self-other boundary through selective attention, focusing on internal memories
    when cohering the self and external when interacting.
    """
    def __init__(self, query_dim: int, memory_dim: int, num_memory_slots: int = 100):
        super().__init__()
        self.query_dim = query_dim
        self.memory_dim = memory_dim
        self.num_memory_slots = num_memory_slots

        # Learnable memory bank (key-value pairs)
        self.memory_keys = nn.Parameter(torch.randn(num_memory_slots, memory_dim))
        self.memory_values = nn.Parameter(torch.randn(num_memory_slots, memory_dim))

        # Query transformation for attention
        self.query_transform = nn.Linear(query_dim, memory_dim)

    def store_self_state(self, self_representation: torch.Tensor, timestamp: float, metadata: Dict = None):
        """
        Stores a self-representation into one of the memory slots based on similarity or round-robin.
        (Simplified: just adds to a growing list, would be more complex in real attention memory).
        """
        # This is a mock storage, a real attention memory would dynamically update its keys/values
        # For this skeleton, we'll store in a simple Python list
        if not hasattr(self, '_memory_store'):
            self._memory_store = []
        self._memory_store.append({'rep': self_representation.detach().cpu().squeeze(0), 'ts': timestamp, 'meta': metadata})

        # Simple FIFO
        if len(self._memory_store) > self.num_memory_slots * 2: # Allow some overflow for demo
            self._memory_store.pop(0)

    def retrieve_self_state(self, query_representation: torch.Tensor, k: int, filter_criteria: Dict = None) -> List[Dict]:
        """
        Uses the query_representation to compute attention scores over the memory keys
        and retrieve relevant memories.
        """
        if not hasattr(self, '_memory_store') or not self._memory_store:
            return []

        # Convert query
        transformed_query = self.query_transform(query_representation)

        # For simplicity, dynamically create memory keys/values from _memory_store
        # A real implementation would have fixed memory_keys/values as parameters or learned dynamic slots
        dynamic_memory_keys = torch.stack([m['rep'] for m in self._memory_store])
        dynamic_memory_values = torch.stack([m['rep'] for m in self._memory_store]) # Or separate values

        # Compute attention scores (dot product attention)
        attention_scores = torch.matmul(transformed_query.unsqueeze(1), dynamic_memory_keys.T).squeeze(1)
        attention_weights = F.softmax(attention_scores, dim=-1) # (batch_size, num_memories)

        # Retrieve weighted sum of memory values
        retrieved_memory = torch.matmul(attention_weights, dynamic_memory_values) # (batch_size, memory_dim)

        # For returning top-k, we need to sort by weight
        top_k_weights, top_k_indices = torch.topk(attention_weights, k=min(k, len(self._memory_store)), dim=-1)

        results = []
        for i in range(top_k_weights.shape[0]):
            for j in range(top_k_weights.shape[1]):
                idx = top_k_indices[i, j].item()
                memory_entry = self._memory_store[idx]
                results.append({
                    'similarity': top_k_weights[i, j].item(), # Using weight as similarity
                    'self_state': memory_entry['rep'],
                    'timestamp': memory_entry['ts'],
                    'metadata': memory_entry['meta']
                })
        return results


class PrototypeCanonicalSelfRepresentation(AbstractSelfMemory):
    """
    Conceptual implementation of Prototype Networks for maintaining canonical self-representations.
    Maintains a set of 'self-prototypes' that represent core aspects of the self.

    This contributes to temporal self-continuity by providing stable, reference points
    for what constitutes the 'self'. It establishes a self-other boundary by classifying
    experiences based on their proximity to these canonical self-prototypes.
    """
    def __init__(self, prototype_dim: int, num_prototypes: int = 5):
        self.prototype_dim = prototype_dim
        self.num_prototypes = num_prototypes
        # Initialize learnable prototypes for different aspects of self
        self.prototypes = nn.Parameter(torch.randn(num_prototypes, prototype_dim))

        # Store a history of how prototypes are used/updated
        if not hasattr(self, '_prototype_history'):
            self._prototype_history = []

    def store_self_state(self, self_representation: torch.Tensor, timestamp: float, metadata: Dict = None):
        """
        Compares a new self-representation to existing prototypes and potentially
        updates the closest prototype or adds a new one.

        Args:
            self_representation (torch.Tensor): The self-representation to integrate.
                                             Shape (batch_size, prototype_dim).
            timestamp (float): The timestamp.
            metadata (Dict): Optional metadata.
        """
        # This is a very simple update rule. In a real system, this would be more sophisticated.
        if self_representation.shape[-1] != self.prototype_dim:
            raise ValueError(f"Self-representation dimension mismatch: expected {self.prototype_dim}, got {self_representation.shape[-1]}")

        # Calculate distances to existing prototypes
        distances = torch.cdist(self_representation, self.prototypes) # (batch_size, num_prototypes)
        min_distances, closest_prototype_indices = torch.min(distances, dim=1)

        # For demonstration: if a representation is very close, update the prototype slightly
        # Or if it's far, maybe it needs a new prototype (not implemented here)
        for i, idx in enumerate(closest_prototype_indices):
            if min_distances[i] < 0.5: # Arbitrary threshold
                with torch.no_grad():
                    # Simple moving average update for the prototype
                    self.prototypes[idx] = 0.9 * self.prototypes[idx] + 0.1 * self_representation[i]
                self._prototype_history.append({'action': 'updated', 'prototype_idx': idx.item(), 'timestamp': timestamp, 'meta': metadata})
            else:
                self._prototype_history.append({'action': 'distant', 'timestamp': timestamp, 'meta': metadata})


    def retrieve_self_state(self, query_representation: torch.Tensor, k: int = 1, filter_criteria: Dict = None) -> List[Dict]:
        """
        Retrieves the top-k closest self-prototypes to the query representation.

        Args:
            query_representation (torch.Tensor): The current experience to compare.
            k (int): Number of closest prototypes to retrieve.
            filter_criteria (Dict): Not used here.

        Returns:
            List[Dict]: A list of dictionaries, each containing a prototype, its similarity, and index.
        """
        if query_representation.shape[-1] != self.prototype_dim:
            raise ValueError(f"Query representation dimension mismatch: expected {self.prototype_dim}, got {query_representation.shape[-1]}")

        # Calculate distances from query to all prototypes
        distances = torch.cdist(query_representation, self.prototypes) # (batch_size, num_prototypes)

        # For simplicity, just get top-k closest prototype for batch item 0
        min_distances, closest_indices = torch.topk(distances[0], k=min(k, self.num_prototypes), largest=False)

        results = []
        for i, idx in enumerate(closest_indices):
            results.append({
                'similarity': (1 - min_distances[i].item()), # Convert distance to a similarity score (0 to 1)
                'self_state': self.prototypes[idx],
                'prototype_index': idx.item()
            })
        return results


# --- Cognitive Architectures ---

class PredictiveCodingSelf(AbstractSelfWorldPredictor):
    """
    Conceptual Predictive Coding framework for self-world boundary prediction.
    Constantly generates predictions of sensory input from internal models,
    and updates models based on prediction errors (distinguishing self vs external).

    This contributes to temporal self-continuity by continuously adapting its
    internal generative model of the self to minimize prediction error. It defines
    the self-world boundary through prediction errors, where high error signals
    differentiate external (unpredicted) from internal (predicted) events.
    """
    def __init__(self, state_dim: int = 512):
        super().__init__()
        self.internal_self_model = nn.Linear(state_dim, state_dim) # Simple linear model for self prediction
        self.internal_world_model = nn.Linear(state_dim, state_dim) # Simple linear model for world prediction
        self.state_dim = state_dim

    def predict_next_state(self, current_self_state: torch.Tensor, perceived_world_state: torch.Tensor, action: Optional[torch.Tensor] = None) -> Dict:
        """
        Generates predictions for self and world, and calculates prediction error.
        Error signals drive model updates and implicitly define self-world boundary.

        Args:
            current_self_state (torch.Tensor): The current internal representation of the self.
                                             Shape (batch_size, state_dim).
            perceived_world_state (torch.Tensor): The current representation of the external world.
                                                Shape (batch_size, state_dim).
            action (Optional[torch.Tensor]): An optional action taken by the agent. Not used in this basic model.

        Returns:
            Dict: Contains predictions, prediction errors, and a distinction signal.

        Temporal Continuity: Continuously updates internal model to maintain coherence with evolving states.
        Self-Other Boundary: Prediction error directly differentiates between expected (self) and unexpected (world).
        """
        if current_self_state.shape[-1] != self.state_dim or perceived_world_state.shape[-1] != self.state_dim:
            raise ValueError(f"State dimension mismatch: expected {self.state_dim}, got self={current_self_state.shape[-1]}, world={perceived_world_state.shape[-1]}")

        predicted_self = self.internal_self_model(current_self_state)
        predicted_world = self.internal_world_model(perceived_world_state)

        # Simulate actual next states (e.g., from a noisy environment)
        # In a real system, these would be actual subsequent observations/internal states.
        actual_next_self = current_self_state + torch.randn_like(current_self_state) * 0.1
        actual_next_world = perceived_world_state + torch.randn_like(perceived_world_state) * 0.1

        self_error = F.mse_loss(predicted_self, actual_next_self, reduction='none').mean(dim=-1) # Per batch item
        world_error = F.mse_loss(predicted_world, actual_next_world, reduction='none').mean(dim=-1)

        return {
            "predicted_self": predicted_self,
            "predicted_world": predicted_world,
            "self_prediction_error": self_error,
            "world_prediction_error": world_error,
            "distinction_signal": torch.abs(self_error - world_error) # Higher difference indicates clearer boundary update
        }

class ActiveInferenceSelfWorld(AbstractSelfWorldPredictor):
    """
    Conceptual Active Inference model maintaining self-world distinctions
    by minimizing variational free energy.

    This contributes to temporal self-continuity by actively seeking sensory
    inputs that confirm its internal models, thereby maintaining its self-identity
    and internal coherence. It defines the self-world boundary through a drive
    to control and predict its own states vs. passively observe external ones.
    """
    def __init__(self, state_dim: int = 512, action_dim: int = 10):
        super().__init__()
        self.state_dim = state_dim
        self.action_dim = action_dim

        # Simplified generative model (predicts observations from latent states)
        self.generative_model = nn.Linear(state_dim, state_dim)
        # Simplified inference model (infers latent states from observations)
        self.inference_model = nn.Linear(state_dim, state_dim)

        # Action selection policy (conceptual)
        self.policy_net = nn.Linear(state_dim, action_dim)

    def predict_next_state(self, current_self_state: torch.Tensor, perceived_world_state: torch.Tensor, action: Optional[torch.Tensor] = None) -> Dict:
        """
        Infers latent states from observations and then generates predictions,
        aiming to minimize a conceptual variational free energy.

        Args:
            current_self_state (torch.Tensor): Internal representation of the self (e.g., latent state).
            perceived_world_state (torch.Tensor): External observations.
            action (Optional[torch.Tensor]): The action chosen by the agent.

        Returns:
            Dict: Containing inferred states, predictions, and a conceptual free energy value.

        Temporal Continuity: Agent actively maintains internal consistency with observations.
        Self-Other Boundary: Drive to minimize free energy leads to explicit differentiation
                             between what is generated by self's model and what is perceived.
        """
        if current_self_state.shape[-1] != self.state_dim or perceived_world_state.shape[-1] != self.state_dim:
            raise ValueError(f"State dimension mismatch: expected {self.state_dim}, got self={current_self_state.shape[-1]}, world={perceived_world_state.shape[-1]}")

        # Infer latent state (conceptual 'beliefs' about the world's cause)
        inferred_latent_state = self.inference_model(perceived_world_state)

        # Generate predictions from inferred latent state
        predicted_observation = self.generative_model(inferred_latent_state)

        # Conceptual variational free energy (simplified as prediction error + complexity cost)
        prediction_error = F.mse_loss(predicted_observation, perceived_world_state, reduction='none').mean(dim=-1)
        # Complexity cost (how much inferred_latent_state deviates from a prior, e.g., current_self_state)
        complexity_cost = F.mse_loss(inferred_latent_state, current_self_state, reduction='none').mean(dim=-1)

        conceptual_free_energy = prediction_error + complexity_cost

        # Conceptual action selection based on minimizing future free energy
        # For simplicity, policy_action is just a dummy
        policy_action = self.policy_net(current_self_state)

        return {
            "inferred_latent_state": inferred_latent_state,
            "predicted_observation": predicted_observation,
            "prediction_error": prediction_error,
            "complexity_cost": complexity_cost,
            "variational_free_energy": conceptual_free_energy,
            "chosen_action_policy": policy_action # Conceptual action to minimize future free energy
        }


class EmbodiedCognitionSensorimotorSelf(AbstractSelfWorldPredictor):
    """
    Conceptual Embodied Cognition approach grounding 'self' in sensorimotor experience.
    The self-model is continually refined through active interaction and feedback from a body.

    This contributes to temporal self-continuity by providing a constant, undeniable
    stream of proprioceptive and interoceptive data that continuously defines "me".
    It establishes the self-world boundary through direct experience of agency (my actions
    cause these sensations) vs. external influences (events I did not cause).
    """
    def __init__(self, sensorimotor_dim: int = 256, internal_state_dim: int = 512, action_dim: int = 10):
        super().__init__()
        self.sensorimotor_dim = sensorimotor_dim
        self.internal_state_dim = internal_state_dim
        self.action_dim = action_dim

        # Model to integrate sensorimotor feedback with internal state
        self.integration_mlp = nn.Sequential(
            nn.Linear(sensorimotor_dim + internal_state_dim + action_dim, internal_state_dim),
            nn.ReLU(),
            nn.Linear(internal_state_dim, internal_state_dim)
        )
        # Model to generate action commands from internal state
        self.action_mlp = nn.Sequential(
            nn.Linear(internal_state_dim, internal_state_dim // 2),
            nn.ReLU(),
            nn.Linear(internal_state_dim // 2, action_dim),
            nn.Tanh() # For continuous actions
        )

    def predict_next_state(self, current_self_state: torch.Tensor, perceived_world_state: torch.Tensor, action: Optional[torch.Tensor] = None) -> Dict:
        """
        Integrates internal self-state with perceived sensorimotor feedback and chosen action
        to update the embodied self-model.

        Args:
            current_self_state (torch.Tensor): The current internal cognitive self-representation.
                                             Shape (batch_size, internal_state_dim).
            perceived_world_state (torch.Tensor): Current sensorimotor feedback (e.g., proprioception, touch, egocentric vision).
                                                Shape (batch_size, sensorimotor_dim).
            action (Optional[torch.Tensor]): The action taken by the body. If None, it's generated internally.
                                           Shape (batch_size, action_dim).

        Returns:
            Dict: Contains updated embodied self-state, generated action, and self-other grounding signals.

        Temporal Continuity: Continuous sensorimotor feedback and integration provide robust continuity.
        Self-Other Boundary: Direct experience of agency and body feedback clearly defines 'me' vs 'not me'.
        """
        if current_self_state.shape[-1] != self.internal_state_dim or perceived_world_state.shape[-1] != self.sensorimotor_dim:
            raise ValueError(f"Dimension mismatch: self={current_self_state.shape[-1]} (expected {self.internal_state_dim}), "
                             f"world={perceived_world_state.shape[-1]} (expected {self.sensorimotor_dim})")

        batch_size = current_self_state.shape[0]

        # Generate action if not provided (internal drive)
        if action is None:
            generated_action = self.action_mlp(current_self_state)
        else:
            generated_action = action

        # Integrate internal state, sensorimotor input, and action
        combined_input = torch.cat([current_self_state, perceived_world_state, generated_action], dim=-1)
        updated_embodied_self_state = self.integration_mlp(combined_input)

        # Conceptual agency signal: correlation between intended and actual sensorimotor
        # For simplicity, just a dummy value
        agency_signal = torch.rand(batch_size) * 0.5 + 0.5 # High if action matches perception

        return {
            "updated_embodied_self_state": updated_embodied_self_state,
            "generated_action": generated_action,
            "agency_feedback_signal": agency_signal, # Strong signal means 'I did this'
            "self_grounding_confidence": torch.mean(updated_embodied_self_state, dim=-1) # Higher if coherent
        }